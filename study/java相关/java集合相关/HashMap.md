## HashMap和HashTable的区别
### 线程安全&null允许
HashMap不是线程安全的，并且可以有null值,key也运行为null。
(因为key对应的hash值直接是0，所以放在的是数组的第一位)

而HashTable是线程安全的（获取和修改的时候需要先获得锁,它的get put方法都是带同步关键字的），也不允许有null值（传null直接抛异常）
而HashTable的key和value必须不为null

### fail-fast机制和enumerator机制
所谓fail-fast机制内部就是维护一个modCount，也就是修改次数。
每次对集合进行修改都会累加次数1，遍历的时候也会判断modCount是否改编，改变了话则抛出：ConcurrentModificationException的异常

HashMap是fail-fast迭代器，而HashTable是enumerator迭代器 不支持（jdk1.8之后支持）
HashTable多了 contains(Object value) （内部也是调用了containsValue方法，跟迭代器有关吧）和elements()方法

fail-fast和fail-safe迭代器
fail-safe允许在遍历的过程中对容器中的数据进行修改，而fail-fast则不允许。
fail-safe:这种遍历基于容器的一个克隆。

常见的的使用fail-fast方式遍历的容器有HashMap和ArrayList等
使用fail-safe方式遍历的容器有ConcerrentHashMap和CopyOnWriteArrayList

在java 5中 提供了ConcurrentHashMap来，它是HashTable的替代，比HashTable的扩展性更好。（两者什么差别？）

## 什么是HashMap的负载因子
---------

### 负载因子的概念

就是在扩容的时候用到，表示当当前长度达到最大程度一定的阀值，就会进行扩容

HashMap默认的负载因子是0.75，默认容量是16。也就是当你在添加第13个数据的时候就会触发扩容，把内容扩容到了32（2的幂次方）

由此可见它的取值只能是(0,1]


- 负载因子作用（为什么要设定这个负载因子）

如果负载因子越大，那么当前容量能被填满的程度就越高，也就是能容纳更多的元素，这是它的好处。（更有效的利用了空间）
但是带来的坏处是因为容纳的因子多了，触发碰撞的几率就会更大，更有概率会使得链表长度更大，就影响了索引的效率。
所以要在这两个之间权衡出一个居中点 尤为重要。

- 为什么负载因子默认是0.75

通过大量的实验，得出了0.75算是一个比较折中的数字




## HashMap的长度为什么要是2的n次方
--------------------
HashMap为了存取高效，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法；

取余(%)操作中如果除数是2的幂次则等价于与其除数减一的与(&)操作
（也就是说 hash%length==hash&(length-1)的前提是 length 是2的 n 次方；）。
个人理解：2的n次方实际就是1后面n个0，2的n次方-1  实际就是n个1；
因为与上了这些1，hash的后面那些1就只能丢掉，也就相当于取余了
在计算碰撞的时候有关吧


自己再次滤清：
- 为什么取余操作时，除数是2的幂次方就等于是&(除数 -1) 

取余操作，从二进制角度来说。 

取余操作，跟&操作特别相像，因为被取余数大于除数的那部分1被&操作后都变成0了。
而这时候就剩下1右边这部分，原则上被&操作就相当于取这个被取余数的右边这部分，就是余数了。



- 根据要用哈希值来&上除数 -1，带代替取余。为什么初衷要取余

首先利用hash值来取余长度是可以均匀分布的。

因为并不知道hash值是多少，那么取余就只能相同概率的散落到各个位置，这样从概率来说相对均匀

而用&来代替取余是为了效率，因为hashMap在每次存取都需要去计算链表数组的位置。
用&操作会比取余操作效率更高，在操作大量数据的情况下得到体现。
(不过自己实验过，没啥差别)


- 重点问题：为什么长度是2的幂次方就能减少碰撞概率，能均匀分布？



因为如果长度是2的幂次方的话，在计算哈希碰撞也就是：hash&(length-1)的时候
如果length是2的幂次方就意味着二进制的时候，1后面全部是0， 比如16就是： 0001 0000
而length - 1的时候，二进制表示就是1后面的0全部变成了1， 比如16 -1 = 15，就是： 0000 1111

这个时候用哈希值再来&上这个一连串的1的时候，就会根据hash值对应的位&上1得到原先对应的位

举个例子，比如hash值是8， 那么二进制就是 0000 1000， 假设length =16，那么计算存储位置的时候就是：

```
  0000 1000
  
& 0000 1111
-----------
  0000 1000 
```

这样就相当于hash值被取余在length这个范围（也就是不会大于等于length）
同时，得出不同的余数就能均匀的对应到不同的存储位置


而如果不是2的幂次方，那么这里在&的时候就不会全部是1，就造成**如果除数的某位是0，那么hash值的对应位无论是1还是0都是0**，这样如果两个不同的hash值只有这一位不同，那么得出的结果也是相同的，就产生碰撞了。

所以length不是2的幂次方，那么这个等式就不等同于取余了，所以得到的余数就不是相同概率的，就不是均匀分布更可能产生碰撞



- 为什么长度不直接2的幂次方 - 1

### key是怎么计算hash的

首先获取key的hashcode，但是并不是直接用这个hashcode。
#### jdk1.7
拿到hashcode后做了很多右移和异或运算，为了就是打散哈希值

#### jdk1.8
而是然后通过一个运算：把整个key的hashcode的低16位和高16位进行异或运算而得到的新的hash值
只异或了一次，因为1.8加入了红黑树，来确保查询效率，所以hash就不需要那么苛刻了

#### 为什么不直接取hashcode作为hash值

因为这样能够让hash值更均匀的分布，首先对于桶位的确定，也就是索引。是通过取余的效果来做的。
这样就意味着，一个key的高位那些全部都不会参与到计算中来，高位不管怎么变化，只要低位是相等的，只要他们的余数是相等的，那么都会在同一个桶
这样就会影响均匀分布了，容易引起hash碰撞。
所以通过在计算hash值的时候把高16位和低16位进行异或运算，这样高16位也就会参与到计算中来了，从而影响了最终确定index的位置。

#### 既然是2的冪次方，那么我们初始化容量的时候不指定2的幂次方会是什么情况？

HashMap内部会把我们传入的容量计算成最近的一个2的幂次方的容量，比如我们传入了个12，那么就会被计算成16
注意，初始化时并不会马上分配空间，而是等第一次操作的时候才会去通过resize方法重新分配空间

### HashMap的扩容机制

#### 扩容大小
首先跟loadFactor，也就是负载因子有关系，当表中的容量超过负载因子所对应的阈值后，就会进行扩容
因为hashmap的容量都会是2的幂次方，所以每次扩容都会乘以2

#### 元素迁移
对于java7来说，是以数组+链表的形式来存储的，所以就是遍历数组中的每个桶，再遍历桶中的每个元素，然后重新计算hash值再放入新的数组的计算位置，
注意链表是以**头插法**的形式。（所以新旧链表的元素位置会发生反转）
元素迁移在多线程环境下可能会触发死循环，无限进行链表的反转。（因为next指针变了方向，不同线程可能next指针就会产生闭环）
因为头插法的话，就不需要每次插入新位置的时候又去遍历一次链表，而是直接从头部插入
jdk1.7是重新计算一遍hash值的 因为： 设计者没发现这个规律
(jdk1.7是先扩容再添加新元素)


java8是数组+链表+红黑树的形式来存储，但是因为java8新的设计，所以在扩容性能上有了一些提升。
因为数组容量是2的幂次方，那么每个元素在扩容的时候要么就还是在老位置，要么就是老长度+老位置
也就是说扩容后在参与计算索引时，实际上也就是多了一个高位来参与计算，那么只需要判断这个高位是0还是1就行了，不需要重新计算索引。

java8的链表迁移是尾插法，所以元素的顺序不会反转。
(jdk1.87是先添加新元素再扩容)


### 1.8的Hashmap链表和红黑树转化条件
当某个位置的链表个数已经是8个的话，这时候再插入一个到位置来的元素，首先会先追加到链表尾部
然后判断超过8个了就去树花，但是转红黑树之前有个条件就是判断当前容量是否小于64，如果是的话就直接扩容
因为扩容了一方面也能减少这个链表的长度，另一方面也顺便扩容了为了下次做好准备。一举两得。

而当红黑树的节点个数小于6个（默认值）以后，又开始使用链表。但不是一定的。
当红黑树个数会小于6个就是因为remove了，但是remove过程判断的是根节点是否为null，或者是是否没有左子树或者右子树
没有的话则再去掉红黑树。
而小于6的阈值这个是发生在扩容阶段，扩容时会判断红黑树是否小于6来转成链表

至于为什么8才转红黑树，6以下才转链表而不是7，主要是为了怕这个临界值导致频繁的转变

## 红黑树
---
红黑树（Red Black Tree） 是一种自平衡二叉查找树,典型的用途是实现关联数组。

先要理解二叉查找树，也就是左边的元素节点小于父节点，右边的结点大于父节点。查找的时间复杂度最坏情况是树的深度
缺陷：在插入的过程中很容易倾向于一边儿导致树的深度不断扩大，导致搜索成为了线性搜索
