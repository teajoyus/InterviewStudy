
# 锁的实现原理
## 缓冲行

CPU缓存，CPU的速度与内存的速度差距是很大的，如果CPU直接去拿内存数据就会很影响性能，所以才有了CPU缓存，L1 L2 L3，也就是寄存器。
而CPU缓存里，**缓存行就是CPU缓存的单元**（最常见的64字节）

## volatile理解

volatile保证了在多处理器环境下共享数据的可见性，也就是说当一个线程修改了该共享变量，另外一个线程能读取到这个修改的值。
（另外一个线程能读取到这个修改的值，是指当另外一个线程已经把共享数据缓存到自己的内存区域后，由于其它线程对该共享数据的修改，自己也能刷新这个值到自己的内存区域里）

如果volatile使用恰当的话，是比synchronized效率要高很多的，因为**它并不会引起线程上下文的切换**

如果一个字段被声明成volatile，Java线程内存模型（IMM）会确保所有线程看到这个变量的值是一致的。
禁止重排序
(在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内 存模型允许volatile变量与普通变量重排序。)

## volatile硬件层原理

当修饰了volatile变量时，在进行写操作的时候，除了语句本身的指令，还会在后面加一个lock指令。
这个指令会触发当前的处理器将缓存行的数据写回到内存中，（如果没有修饰volatile的话，那么就不一定是马上写回内存的）

第二个是：这个写回内存的操作会使得其它处理器缓存了该地址的数据无效。
（为什么能知道无效呢？下面回答）
但是就算写回内存，其它CPU在之前缓存了此变量的数据还是旧的，
所以说为了确保每个处理器的缓存是一致的，就有了一个缓存一致性的协议，也就是：每个处理器都能嗅探在总线上传播的数据来检查自己的值是不是被修改了，
当发现被修改的话，就会把这个缓存行判定为无效状态，下次处理需要读取这个数据的时候因为无效状态就会去内存中把数据读取到缓存行中来。

## synchronized的实现

### 指令实现
JVM是基于进入和退出Monitor对象来实现同步的。代码块是用一对指令，叫monitorenter和monitorexit来实现的
monitorenter指令会插入在同步代码的起始位置，monitorexit是插入到结束为止或异常位置，
如果一个monitor对象被持有，那么就处于锁定状态。
当线程执行到moitorenter指令时，就会尝试去获取对象所对应的monitor

### 对象头存放锁
 synchronized用的锁是存放在对象头里面的（对象如果是数组，那么是3个字宽，如果是普通对象就是2字宽）
 
 在JDK1.6起为了减少锁带来的性能消耗，就引入了偏向锁和轻量级锁。
 锁总共有4种状态等级：无锁、偏向锁、轻量级锁、重量级锁。这些锁会随着竞争的情况逐渐升级，并且不能降级（为了提高获得锁和释放锁的效率），
 
 #### 偏向锁
 偏向锁：当一个线程访问一个同步块时，会在对象头和栈帧的锁记录里记录偏向的线程id，之后该线程在进入和退出锁的时候就不需要再参与CAS竞争了，
 直接判断对象头里是否存储着偏向锁所偏向的线程id，如果是自己那么就表示已经获得了锁，如果不是，那么就需要判断偏向锁的标识是否为1，如果没有设置，
 则参与CAS竞争锁，如果是，则尝试将对象头的偏向锁指向当前线程（最后一句话并不理解）
 https://www.icode9.com/content-1-714818.html
 偏向锁除非有竞争出现才会释放锁，当其它线程来竞争时，就先暂停拥有偏向锁的线程。有几种情况
 一种是如果线程A不存活了，那么偏向锁就被撤销为无锁状态，其它线程再来竞争锁
 一种是线程A还存活着，那么会判断该线程是否还需要竞争锁（遍历栈帧中的锁记录），如果不竞争，那么B获得偏向锁，如果竞争的话，那么就升级成轻量级锁
 另外一种是线程A还存活着，但是markword里的epoch值大于40，就直接升级成轻量级锁，epoch字段表示偏向锁撤销的次数
 
 ### 轻量级锁
 
 #### 获取锁
 线程在执行同步代码块之前，会把对象头markword复制到栈帧的锁记录中，然后尝试使用CAS将对象头的markword替换为指向这个锁记录的指针，如果替换成功了说明获得了锁。
 如果替换失败，说明其它线程参与竞争了拿到锁了，那么当前线程就会继续自旋来尝试获取锁
 
 #### 释放锁
 释放轻量级锁时，会使用CAS操作把栈帧的锁记录中之前存放的markword副本再替换回来对象头，如果成功表示没有竞争，如果失败，表示锁存在竞争，锁会升级成重量级锁（不会降级）
 这时，参与锁竞争的线程会被阻塞，而持有锁的线程在释放锁之后会唤醒这些线程，然后进入下一轮竞争。
 
 ### 重量级锁
 
 就是在轻量级锁在释放锁时存在竞争，那么就会升级成重量级锁，重量级锁会让线程阻塞，直到持有锁的线程释放了锁之后唤醒其它参与锁竞争的线程
 
 ## CAS  Compare And Swap
 ### 解释
 CAS过程中有两个操作数，一个是旧值（也就是期望操作前的值），一个是新值，也就是期望操作后的值。
 在操作期间先比较旧值有没有发生变化，如果发生变化了则不交换，如果没发生变化蔡才替换成新值。
 
 （关于CAS 还需要继续写其它知识点相关的）
 （处理器有一个CMPXCHG指令来实现CAS）
 
 ### 问题以及解决方案（局限性）
 - ABA问题（每次比较只能比较旧值是否与当前相等，但是也没办法知道当前值是否有过修改后再还原成旧值）
   解决方法：使用版本号，每次修改了一次就追加一次版本号   （从jdk1.5开始，jdk中的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。）
 - 循环时间长开销大
   解决方法：这个也办法避免，如果说JVM能直接支持CAS失败时做CPU延迟可能会好一点，比如pause指令
 
 - 每次只能保证一个共享变量的原子操作
  解决方法： 可以把多个共享对象和并成一个对象。（从Java 1.5开始， JDK提供了AtomicReference类来保证引用对象之间的原子性）
 
 ## 处理器如何实现原子操作
 
 1、使用总线锁来保证原子性。当处理器对总线发出一个LOCK信号，那么其它处理器的请求就会被阻塞住（开销太大，不利于性能）
 2、使用缓存锁来保证原子性。（为了性能，部分场景用缓存锁来代替总线锁，以减少性能消耗）
 当某个内存区域的数据被缓存到CPU缓存行中时，处理器在将缓存行写回内存的过程中会修改内部的内存地址，导致其它处理器缓存了这个区域数据的缓存行无效。
 （如果有些操作不支持缓存到处理器，或者处理器不支持缓存锁定）
 
 
## java中实现原子操作
1、利用循环CAS实现原子操作
 

# Java中的内存模型（JMM）

线程/进程间的通信方式：
- 信号
- 信号量
- 消息队列（消息传递）
- 管道
（管道有很多致命的缺点，比如只能在具有亲缘关系的进程间通信，只能单向传输数据，另外管道的缓冲区是有限的）
- 共享内存

而Java的并发采用的是共享内存模型。线程之间的通信是隐式进行的

在堆内存中是线程共享的，而他们的通信方式由JMM来决定的，JMM处理了当一个线程对共享对象的修改何时对另外线程可见的问题。
或者抽象来说，JMM是定义了线程与内存之间的抽象关系：共享变量是存放于内存中，每个线程都有一个私有的本地内存区域，他们存储了共享变量的副本。
当两个线程进行通信，是线程A在本地内存区域把修改后的共享变量刷新到内存中，线程B再从主内存中把共享变量刷新到自己的本地内存区域中。
**JMM通过控制内存与这两个线程的本地内存区域的交互，来提供内存可见性的一种保证。**

## 指令重排序

- 来自编译器优化的重排序
- 指令在并行时的重排序
- 内存系统的重排序
JMM通过禁止一些特定的重排序来保证内存可见性（Java编译器在生成指令序列的适当位置会**插入内存屏障指令**来禁止特定类型的处理器重排序。）

## happens-before 规则
 根据happens-before 规则来禁止一些指令的重排序
 比如volatile就禁止了重排序
 ## as- if-serial语义
 不管怎么重排序，程序的执行结果不能被改变，如果两个操作之间存在数据依赖性（至少有一个写操作），那么是不能重排序的。
 
 ## 未同步的多线程程序，提供最小安全性
  JMM保证了一个线程读取到的值，要么是之前某个线程修改的值 要么是默认值，而不会读取到脏数据。
  JVM在堆上分配内存的时候，会首先对这段内存空间进行清零，然后再分配（而JVM内部自己会同步这两个操作）
  
## JMM不保证对64位的long型和double型变量的写操作具有原子性，而顺序一致性模型保 证对所有的内存读/写操作都具有原子性。
 